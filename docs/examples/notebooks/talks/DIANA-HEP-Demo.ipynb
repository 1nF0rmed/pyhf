{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `pyhf` Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello World, `pyhf` style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Two bin counting experiment with a background uncertainty:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyhf\n",
    "import pyhf.simplemodels\n",
    "import pyhf.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pyhf version 0.0.15\n"
     ]
    }
   ],
   "source": [
    "print('Using pyhf version {}'.format(pyhf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed: [0.05290116] Expected: [0.06445521]\n"
     ]
    }
   ],
   "source": [
    "pdf = pyhf.simplemodels.hepdata_like(signal_data=[12.,11.], bkg_data=[50.,52.], bkg_uncerts=[3.,7.])\n",
    "CLs_obs, CLs_exp = pyhf.utils.hypotest(\n",
    "        1.0, [51, 48] + pdf.config.auxdata, pdf,\n",
    "        return_expected=True)\n",
    "print('Observed: {} Expected: {}'.format(CLs_obs, CLs_exp))\n",
    "numpy_results = CLs_obs, CLs_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What backend is being used?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<pyhf.tensor.numpy_backend.numpy_backend at 0x7f71a42bd390>,\n",
       " <pyhf.optimize.opt_scipy.scipy_optimizer at 0x7f71a42bd470>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyhf.get_backend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Switch out to a different backend**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "pyhf.set_backend(pyhf.tensor.tensorflow_backend(session=sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<pyhf.tensor.tensorflow_backend.tensorflow_backend at 0x7f7172598c88>,\n",
       " <pyhf.optimize.opt_tflow.tflow_optimizer at 0x7f716394f7f0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyhf.get_backend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**and reproduce the same result as with the NumPy backend**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcf/miniconda3/envs/pyhf/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/mcf/miniconda3/envs/pyhf/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/mcf/miniconda3/envs/pyhf/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed: [0.05257673] Expected: [0.06445909]\n"
     ]
    }
   ],
   "source": [
    "CLs_obs, CLs_exp = pyhf.utils.hypotest(1.0, [51, 48] + pdf.config.auxdata, pdf, return_expected=True)\n",
    "print('Observed: {} Expected: {}'.format(sess.run(CLs_obs), sess.run(CLs_exp)))\n",
    "tensorflow_results = sess.run(CLs_obs), sess.run(CLs_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A comparison:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# NumPy\n",
      "Observed: [0.05290116] Expected: [0.06445521]\n",
      "\n",
      "# TensorFlow\n",
      "Observed: [0.05257673] Expected: [0.06445909]\n"
     ]
    }
   ],
   "source": [
    "backends = ['NumPy', 'TensorFlow']\n",
    "results = [numpy_results, tensorflow_results]\n",
    "for backend, result in zip(backends, results):\n",
    "    print('\\n# {}\\nObserved: {} Expected: {}'.format(backend, result[0], result[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differences result of using single float precision versus double float precision (WIP to harmonize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $CL_{s}$ Example using pyhf CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use some preexisiting files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[00mdemo.json\u001b[0m  \u001b[00mnew_signal.json\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Use some shell magics in Jupyter\n",
    "% ls *.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**JSON defining a single channel, two bin counting experiment with systematics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"channels\": [{\r\n",
      "        \"name\": \"singlechannel\",\r\n",
      "        \"samples\": [{\r\n",
      "                \"name\": \"sig\",\r\n",
      "                \"data\": [12.0, 11.0],\r\n",
      "                \"modifiers\": [{\r\n",
      "                    \"name\": \"mu\",\r\n",
      "                    \"data\": null,\r\n",
      "                    \"type\": \"normfactor\"\r\n",
      "                }]\r\n",
      "            },\r\n",
      "            {\r\n",
      "                \"name\": \"bkg\",\r\n",
      "                \"data\": [50.0, 52.0],\r\n",
      "                \"modifiers\": [{\r\n",
      "                    \"name\": \"uncorr_bkguncrt\",\r\n",
      "                    \"data\": [3.0, 7.0],\r\n",
      "                    \"type\": \"shapesys\"\r\n",
      "                }]\r\n",
      "            }\r\n",
      "        ]\r\n",
      "    }],\r\n",
      "    \"data\": {\r\n",
      "        \"singlechannel\": [51.0, 48.0]\r\n",
      "    },\r\n",
      "    \"toplvl\": {\r\n",
      "        \"measurements\": [{\r\n",
      "            \"config\": {\r\n",
      "                \"poi\": \"mu\"\r\n",
      "            },\r\n",
      "            \"name\": \"singlechannel\"\r\n",
      "        }]\r\n",
      "    }\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "% cat demo.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"CLs_exp\": [\r\n",
      "        0.0026064088679956573,\r\n",
      "        0.013820657528619459,\r\n",
      "        0.06445521290832801,\r\n",
      "        0.2352610362693783,\r\n",
      "        0.5730418174887743\r\n",
      "    ],\r\n",
      "    \"CLs_obs\": 0.05290116224852556\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "# Use more shell magics to run from the command line\n",
    "! pyhf cls demo.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Can also pipe a file to `pyhf` (think [HEPData](https://hepdata.net/))**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://raw.githubusercontent.com/diana-hep/pyhf/talk/DIANA-HEP-talk/docs/examples/notebooks/talks/demo.json\r\n"
     ]
    }
   ],
   "source": [
    "json_url=\"https://raw.githubusercontent.com/diana-hep/pyhf/talk/DIANA-HEP-talk/docs/examples/notebooks/talks/demo.json\"\n",
    "! echo \"{json_url}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   836  100   836    0     0   2999      0 --:--:-- --:--:-- --:--:--  2996\n",
      "{\n",
      "    \"CLs_exp\": [\n",
      "        0.0026064088679956573,\n",
      "        0.013820657528619459,\n",
      "        0.06445521290832801,\n",
      "        0.2352610362693783,\n",
      "        0.5730418174887743\n",
      "    ],\n",
      "    \"CLs_obs\": 0.05290116224852556\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "! curl \"{json_url}\" | pyhf cls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $CL_{s}$ with Reinterpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Original output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;39m0.05290116224852556\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pyhf cls demo.json | jq .CLs_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consider a new signal to test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\r\n",
      "    \"op\": \"replace\",\r\n",
      "    \"path\": \"/channels/0/samples/0/data\",\r\n",
      "    \"value\": [5.0, 6.0]\r\n",
      "}]\r\n"
     ]
    }
   ],
   "source": [
    "% cat new_signal.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply the patch with the new signal to update the likelihood: $L \\to L'$**\n",
    "\n",
    "- Using the [RFC 6902 (JSON Patch) standard](https://tools.ietf.org/html/rfc6902)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;39m0.34015787575273343\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pyhf cls demo.json --patch new_signal.json | jq .CLs_obs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
